# -*- coding: utf-8 -*-
"""Simplified Code - Ethan

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AzMM43yux58mM48W2LwC9l3UtLXVw9Ai

Initial Stuff:
"""

# libraries:
library(ggplot2)
library(dplyr)
library(readxl)
library(tidyr)
library(stringr)

# Load data from the Excel file
Mixed_Beverage_Gross_Receipts <- read.csv("Mixed_Beverage_Gross_Receipts.csv")

# Filter for only Austin
data <- Mixed_Beverage_Gross_Receipts

"""Model 2:"""

install.packages(c("tidyverse", "forecast"))

# Sample a subset of the data (adjust the fraction as needed)
set.seed(69)
sampled_data <- data %>% sample_frac(0.05)  # This samples 5% of the data

# Filter out rows with missing data in Responsibility.End.Date
sampled_data <- sampled_data %>% filter(!is.na(Responsibility.End.Date) & Responsibility.End.Date != "")

# Convert date columns to Date type
sampled_data$Responsibility.Begin.Date <- as.Date(sampled_data$Responsibility.Begin.Date, format = "%m/%d/%Y")
sampled_data$Responsibility.End.Date <- as.Date(sampled_data$Responsibility.End.Date, format = "%m/%d/%Y")
sampled_data$Obligation.End.Date <- as.Date(sampled_data$Obligation.End.Date, format = "%m/%d/%Y")

# Create a new variable for operation duration
sampled_data$Operation_Duration <- as.numeric(difftime(sampled_data$Responsibility.End.Date, sampled_data$Responsibility.Begin.Date, units = "days"))

# Explore the structure of the sampled data
str(sampled_data)

# Explore the summary statistics of numeric variables
summary(sampled_data)

# Assuming daily frequency, adjust as needed
sales_ts_downsampled <- ts(sampled_data$Total.Receipts,
                           start = min(sampled_data$Responsibility.Begin.Date),
                           end = max(sampled_data$Responsibility.End.Date),
                           frequency = 365)  # Assuming daily data

# Downsample to daily frequency
sales_ts_downsampled <- aggregate(sales_ts_downsampled, nfrequency = 1, FUN = mean)

# Plot the downsampled time series
plot(sales_ts_downsampled)

# Assuming `sales_ts_downsampled` is your downsampled time series data

# Train-Test Split (using 80% for training)
train_size <- floor(0.8 * length(sales_ts_downsampled))
train_data <- window(sales_ts_downsampled, end = c(train_size))

# Model Training (using ARIMA)
library(forecast)
model <- auto.arima(train_data)

# Summary of the trained model
summary(model)

# Test set
test_data <- window(sales_ts_downsampled, start = (train_size + 1))

# Forecast on the test set
forecast_values <- forecast(model, h = length(test_data))

# Evaluate performance
accuracy_values <- accuracy(forecast_values, test_data)
accuracy_values